{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/03_pytorch_computer_vision_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vex99np2wFVt"
      },
      "source": [
        "# 03. PyTorch Computer Vision Exercises\n",
        "\n",
        "The following is a collection of exercises based on computer vision fundamentals in PyTorch.\n",
        "\n",
        "They're a bunch of fun.\n",
        "\n",
        "You're going to get to write plenty of code!\n",
        "\n",
        "## Resources\n",
        "\n",
        "1. These exercises are based on [notebook 03 of the Learn PyTorch for Deep Learning course](https://www.learnpytorch.io/03_pytorch_computer_vision/). \n",
        "2. See a live [walkthrough of the solutions (errors and all) on YouTube](https://youtu.be/_PibmqpEyhA). \n",
        "  * **Note:** Going through these exercises took me just over 3 hours of solid coding, so you should expect around the same.\n",
        "3. See [other solutions on the course GitHub](https://github.com/mrdbourke/pytorch-deep-learning/tree/main/extras/solutions)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaeYzOTLwWh2",
        "outputId": "17dd5453-9639-4b01-aa18-7ddbfd5c3253"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'nvidia-smi' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "# Check for GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "DNwZLMbCzJLk",
        "outputId": "9c150c50-a092-4f34-9d33-b45247fb080d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.0.1+cpu\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import torch\n",
        "import torch\n",
        "\n",
        "# Exercises require PyTorch > 1.10.0\n",
        "print(torch.__version__)\n",
        "\n",
        "# TODO: Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSFX7tc1w-en"
      },
      "source": [
        "## 1. What are 3 areas in industry where computer vision is currently being used?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyWRkvWGbCXj"
      },
      "source": [
        "Computer vision is widely being used in many industries. Some of the main industries in which it finds its applications include:\n",
        "* Healthcare - for cancer detection, CT and MRI scanning\n",
        "* Transportation - Self driving cars, road condition monitoring etc.\n",
        "* Agriculture - crop monitoring, deweeding, plant disease detection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBK-WI6YxDYa"
      },
      "source": [
        "## 2. Search \"what is overfitting in machine learning\" and write down a sentence about what you find. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1rxD6GObCqh"
      },
      "source": [
        "Overfitting is an undesirable machine learning behavior that occurs when a model gives accurate prediction for training data but not new data.\n",
        "\n",
        "Overfitting occurs when the model cannot generalize and fits too closely to the training dataset instead."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeYFEqw8xK26"
      },
      "source": [
        "## 3. Search \"ways to prevent overfitting in machine learning\", write down 3 of the things you find and a sentence about each. \n",
        "> **Note:** there are lots of these, so don't worry too much about all of them, just pick 3 and start with those."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocvOdWKcbEKr"
      },
      "source": [
        "* Early stopping - Early stopping pauses the training phase before the machine learning model learns the noise in the data.\n",
        "* Pruning - feature selection or pruning identifies the most important features within the training set and eleminates irrelevant ones.\n",
        "* Regularization - these methods try to eleminate those factors that do not impact the prediction outcomes by grading features based on importance. eg : mathemitical calculations apply a penalty value to features with minimal impact."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKdEEFEqxM-8"
      },
      "source": [
        "## 4. Spend 20-minutes reading and clicking through the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/).\n",
        "\n",
        "* Upload your own example image using the \"upload\" button on the website and see what happens in each layer of a CNN as your image passes through it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqZaJIRMbFtS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvf-3pODxXYI"
      },
      "source": [
        "## 5. Load the [`torchvision.datasets.MNIST()`](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST) train and test datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SHjeuN81bHza"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.0.1+cpu\n",
            "0.15.2+cpu\n"
          ]
        }
      ],
      "source": [
        "from torch import nn\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Check version\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data = datasets.MNIST(root = \"data\",\n",
        "                            train = True,\n",
        "                            download = True,\n",
        "                            transform= ToTensor())\n",
        "test_data = datasets.MNIST(root= \"data\",\n",
        "                           train = False,\n",
        "                           download = True,\n",
        "                           transform = ToTensor())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 10000)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_data), len(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
              "           0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
              "           0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
              "           0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
              "           0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
              "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
              "           0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
              "           0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
              "           0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
              "           0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
              "           0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
              "           0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
              "           0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
              "           0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
              "           0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
              "           0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
              "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
              "           0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
              "           0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
              " 5)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image, label = train_data[0]\n",
        "image,label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['0 - zero',\n",
              " '1 - one',\n",
              " '2 - two',\n",
              " '3 - three',\n",
              " '4 - four',\n",
              " '5 - five',\n",
              " '6 - six',\n",
              " '7 - seven',\n",
              " '8 - eight',\n",
              " '9 - nine']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_names = train_data.classes\n",
        "class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'0 - zero': 0,\n",
              " '1 - one': 1,\n",
              " '2 - two': 2,\n",
              " '3 - three': 3,\n",
              " '4 - four': 4,\n",
              " '5 - five': 5,\n",
              " '6 - six': 6,\n",
              " '7 - seven': 7,\n",
              " '8 - eight': 8,\n",
              " '9 - nine': 9}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_to_idx = train_data.class_to_idx\n",
        "class_to_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image Shape: torch.Size([1, 28, 28]) [C:H:W]\n",
            "Image Label: 5 - five\n"
          ]
        }
      ],
      "source": [
        "# Check the shape of our image\n",
        "print(f\"Image Shape: {image.shape} [C:H:W]\")\n",
        "print(f\"Image Label: {class_names[label]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image shape: torch.Size([1, 28, 28])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot an image\n",
        "import random\n",
        "indx = random.randint(0,len(train_data)-1)\n",
        "image,label = train_data[indx]\n",
        "print(f\"Image shape: {image.shape}\")\n",
        "plt.title(class_names[label])\n",
        "plt.imshow(image.squeeze(),cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxZW-uAbxe_F"
      },
      "source": [
        "## 6. Visualize at least 5 different samples of the MNIST training dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QVFsYi1PbItE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image Shape: torch.Size([1, 28, 28])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image Shape: torch.Size([1, 28, 28])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image Shape: torch.Size([1, 28, 28])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image Shape: torch.Size([1, 28, 28])\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAERCAYAAABSGLrIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAK10lEQVR4nO3dX2jV9R/H8dfpbDplbrqDoOjUKZveeCF2pzaNuSRDVOQgWksTSqxwxhCVYE42RJzalUFepJAXassKIS/8E3nRP5SoFahhA/FPkBlNLGvb93fx6zfYT/18z2nHnbnX8wFebO/vOd/PqKcft+853yWiKIoEYEh7It8LAPDoETpggNABA4QOGCB0wAChAwYIHTBA6IABQgcMEDruk0gktH379nwvAzlE6Hl2/vx5LVq0SCUlJRo1apRqa2v1zTff5HtZGGISvNY9fy5cuKA5c+aovLxcr7zyinp6erR//379+uuv+uqrrzR9+vS8rOvPP/9UQUGBCgoK8nJ+5B6h59HixYv1+eef6/Lly0qlUpKkGzduqKqqSrW1tWpra8vzCjFU8E/3PDp37pxqamp6I5ek8ePHq7q6WidOnNCdO3dydq41a9aouLhY165d09KlS1VcXKyxY8eqoaFB3d3dfY79/+/Rt2/frkQioR9//FFr1qzR6NGjVVpaqrVr1+ru3bv3neu9997T7NmzNWLECJWVlWnlypW6evVqzr4WZI/Q8+jevXsaMWLEfZ8fOXKk/vrrL7W3t+f0fN3d3XrmmWeUSqXU2tqq6upq7dmzR++8805Gj0+n0+rs7NTOnTuVTqd18OBBNTU19TmmpaVFdXV1qqys1N69e1VfX6/Tp0/rqaee0m+//ZbTrwdZiJA3M2fOjKqqqqKurq7ez927dy+aNGlSJCl6//33c3auF198MZIU7dixo8/nZ82aFc2ePbvP5yRFjY2NvR83NjZGkqKXXnqpz3HLli2LUqlU78cdHR1RMpmMWlpa+hz33XffRQUFBfd9HgOHHT2PNmzYoEuXLmndunX64Ycf1N7errq6Ot24cUOS9Mcff+T8nOvXr+/z8bx583TlypV//dhbt27p999/lyR98MEH6unpUTqd1i+//NL7Z9y4caqsrNTZs2dz80Uga/xYNY/Wr1+vq1evavfu3Tp06JAk6cknn9TmzZvV0tKi4uLihz72zp07fb6HTyaTGjt2bPB8RUVF9x0zZswY3b59O6P1Tpo06b7HStLt27dVUlKiy5cvK4oiVVZWPvDxhYWFGZ0HuUfoedbS0qKGhgZ9//33Ki0t1cyZM7Vt2zZJUlVV1UMf19ra2uf748mTJ6ujoyN4rmQy2a+1Puzx0T8Xbnp6epRIJPTJJ5888NjQX1x4tAh9EBgzZozmzp3b+/GpU6c0ceJEzZgx46GPqaur6/OYB/1Qb6BNmzZNURSpoqIi+JcUBh7fow8yR44c0ddff636+no98cTD//NMnTpVNTU1vX/mzJkzgKt8sOXLlyuZTKqpqal3l/+fKIp069atPK0M7Oh59Nlnn2nHjh2qra1VKpXSF198oXfffVeLFi3Sxo0b8728rE2bNk3Nzc3aunWrOjo6tHTpUo0aNUo//fSTjh8/rpdfflkNDQ35XqYlQs+jCRMmKJlMavfu3ers7FRFRYWam5v1xhtvPLYvP92yZYuqqqq0b9++3p8hlJeXq7a2VkuWLMnz6nzxEljAAN+jAwYIHTBA6IABQgcMEDpggNABA4QOGMj4VRmJROJRrgPAv5TJS2HY0QEDhA4YIHTAAKEDBggdMEDogAFCBwwQOmCA0AEDhA4YIHTAAKEDBggdMEDogAFCBwwQOmCA0AEDhA4YIHTAAKEDBggdMEDogAFCBwwQOmCA0AEDhA4YIHTAAKEDBggdMEDogAFCBwwQOmCA0AEDhA4YIHTAAKEDBggdMEDogAFCBwwQOmCA0AEDhA4YIHTAAKEDBggdMEDogAFCBwwQOmCA0AEDhA4YIHTAAKEDBggdMEDogAFCBwwQOmCA0AEDBfleAHJvypQpwfm4ceNin2PdunXB+YoVK4Lz0aNHB+ebNm2KXcNbb70Vewwyw44OGCB0wAChAwYIHTBA6IABQgcMEDpgIBFFUZTRgYnEo14L/rFly5bgfNWqVcH5+PHjg/OysrLYNfT09ATn3d3dwXlhYWFwfvPmzdg1TJgwIfYYSJkkzI4OGCB0wAChAwYIHTBA6IABQgcMEDpggPej51hRUVFw3tTUFPsc9fX1wXncNepPP/00OI+7Bi5Ju3btCs43btwYnD/77LPB+fXr12PXgNxhRwcMEDpggNABA4QOGCB0wAChAwYIHTDAdfQcO3DgQHC+evXq2Ofo6uoKzrdt2xacx10DHzlyZOwampubg/OFCxcG53H3L9i7d2/sGpA77OiAAUIHDBA6YIDQAQOEDhggdMAAoQMGCB0wwC9wyNKyZcuC88OHDwfncTemkKTNmzcH562trcF5aWlpcN7W1ha7hqeffjo4z/B/m4e6dOlS7DHPP/98cH7+/Pl+rWGo4Bc4AJBE6IAFQgcMEDpggNABA4QOGCB0wAA3nsjS8uXLg/Phw4cH51euXIk9x8WLF4PzV199NThPp9PB+dy5c2PX8KhNnz499pi4X2Txwgsv5Gg1Qx87OmCA0AEDhA4YIHTAAKEDBggdMEDogAGuo2dp3759wXncdfaKiorYc3z44YfBedy9Afr7XvFMnDlzJjiPez97Jn7++ed+Pwf+ix0dMEDogAFCBwwQOmCA0AEDhA4YIHTAANfRs3ThwoXgvLGxMThfu3Ztv9dw4sSJ4PzmzZvB+UcffRR7jrt37wbnr7/+enAedx392LFjsWvYv39/7DHIDDs6YIDQAQOEDhggdMAAoQMGCB0wQOiAAUIHDCSiDO9SEHezAwwtJSUlwfm3334bnJeXlwfnr732Wuwa3n777dhjkNmNRtjRAQOEDhggdMAAoQMGCB0wQOiAAUIHDHDjCTzQggULgvO46+Tnzp0Lzg8fPpz1mvDvsaMDBggdMEDogAFCBwwQOmCA0AEDhA4Y4P3ohgoLC2OPuX79enBeVlYWnKfT6eC8ra0tdg3IDO9HByCJ0AELhA4YIHTAAKEDBggdMEDogAHej26ouro69phUKhWcX7x4MTjnOvngwo4OGCB0wAChAwYIHTBA6IABQgcMEDpggNABA7xgZghKJpPB+Ztvvtnvc+zcubPfz4GBw44OGCB0wAChAwYIHTBA6IABQgcMEDpggOvoQ9DixYuD83nz5sU+x6lTp4Lz48ePZ7Um5Bc7OmCA0AEDhA4YIHTAAKEDBggdMEDogAGuow9BW7du7fdzHDhwIDjv7Ozs9zkwcNjRAQOEDhggdMAAoQMGCB0wQOiAAUIHDCSiKIoyOjCReNRrQYZqamqC85MnTwbnXV1dsecoKirKak3In0wSZkcHDBA6YIDQAQOEDhggdMAAoQMGCB0wQOiAAW48MQgNGzYsOF+5cmVw/vfffwfnGzZsyHpNeLyxowMGCB0wQOiAAUIHDBA6YIDQAQOEDhjgxhOD0HPPPRecf/zxx8H50aNHg/O46/B4vHDjCQCSCB2wQOiAAUIHDBA6YIDQAQOEDhjg/eiD0Pz584PzL7/8Mjhvbm7O4WowFLCjAwYIHTBA6IABQgcMEDpggNABA4QOGOA6+gCbOnVq7DErVqwIzjdt2hSct7e3Z7UmDH3s6IABQgcMEDpggNABA4QOGCB0wAChAwYIHTDAL3AAHnP8AgcAkggdsEDogAFCBwwQOmCA0AEDhA4YyPjGExlebgcwCLGjAwYIHTBA6IABQgcMEDpggNABA4QOGCB0wAChAwb+A9VDyShimrk5AAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image Shape: torch.Size([1, 28, 28])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for i in range(5):\n",
        "    indx=random.randint(0,len(train_data)-1)\n",
        "    image,label = train_data[indx]\n",
        "    print(f\"Image Shape: {image.shape}\")\n",
        "    plt.figure(figsize=(3,3))\n",
        "    plt.imshow(image.squeeze(),cmap='gray')\n",
        "    plt.title(class_names[label])\n",
        "    plt.axis(False)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPDzW0wxhi3"
      },
      "source": [
        "## 7. Turn the MNIST train and test datasets into dataloaders using `torch.utils.data.DataLoader`, set the `batch_size=32`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ALA6MPcFbJXQ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x1bb8a081ff0>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x1bb8a082950>)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_dataloader = DataLoader(dataset=train_data,\n",
        "                              batch_size=32,\n",
        "                              shuffle=True)\n",
        "test_dataloader = DataLoader(dataset=test_data,\n",
        "                             batch_size=32,\n",
        "                             shuffle=False)\n",
        "train_dataloader, test_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 1, 28, 28])\n",
            "torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "for sample in next(iter(train_dataloader)):\n",
        "    print(sample.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1875, 313)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_dataloader), len(test_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCCVfXk5xjYS"
      },
      "source": [
        "## 8. Recreate `model_2` used in notebook 03 (the same model from the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/), also known as TinyVGG) capable of fitting on the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5IKNF22XbKYS"
      },
      "outputs": [],
      "source": [
        "class MNISTModelV0(nn.Module):\n",
        "    '''\n",
        "    Model architecture that replicates TinyVGG\n",
        "    '''\n",
        "    def __init__(self,input_shape: int, hidden_units: int, output_shape: int):\n",
        "        super().__init__()\n",
        "        self.conv_block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels= input_shape,\n",
        "                      out_channels= hidden_units,\n",
        "                      kernel_size= 3,\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels= hidden_units,\n",
        "                      out_channels= hidden_units,\n",
        "                      kernel_size= 3,\n",
        "                      stride= 1,\n",
        "                      padding= 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2,\n",
        "                         stride= 2)\n",
        "        )\n",
        "        \n",
        "        self.conv_block_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels= hidden_units,\n",
        "                      out_channels= hidden_units,\n",
        "                      kernel_size=3,\n",
        "                      stride= 1,\n",
        "                      padding= 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels= hidden_units,\n",
        "                      out_channels= hidden_units,\n",
        "                      kernel_size= 3,\n",
        "                      stride= 1,\n",
        "                      padding= 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size= 2)\n",
        "        )\n",
        "        \n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features= hidden_units*7*7,\n",
        "                      out_features= output_shape)\n",
        "        )\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x = self.conv_block_1(x)\n",
        "        # print(x.shape)\n",
        "        x = self.conv_block_2(x)\n",
        "        # print(x.shape)\n",
        "        x= self.classifier(x)\n",
        "        # print(x.shape)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MNISTModelV0(\n",
              "  (conv_block_1): Sequential(\n",
              "    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv_block_2): Sequential(\n",
              "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=490, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "model_0 = MNISTModelV0(input_shape=1,\n",
        "                       hidden_units= 10,\n",
        "                       output_shape= len(class_names)).to(device)\n",
        "model_0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 28, 28])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rand_image_tensor = torch.randn(size=(1,28,28)).unsqueeze(0).to(device)\n",
        "rand_image_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.0366, -0.0940,  0.0686, -0.0485,  0.0068,  0.0290,  0.0132,  0.0084,\n",
              "         -0.0030, -0.0185]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_0(rand_image_tensor.to(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf_3zUr7xlhy"
      },
      "source": [
        "## 9. Train the model you built in exercise 8. for 5 epochs on CPU and GPU and see how long it takes on each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "jSo6vVWFbNLD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Gaurav\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            " 20%|        | 1/5 [00:58<03:52, 58.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 | Average train loss: 0.421 | Avg test loss: 0.115\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|      | 2/5 [01:54<02:50, 56.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 | Average train loss: 0.080 | Avg test loss: 0.070\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|    | 3/5 [02:50<01:52, 56.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 2 | Average train loss: 0.063 | Avg test loss: 0.054\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|  | 4/5 [03:46<00:56, 56.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 3 | Average train loss: 0.054 | Avg test loss: 0.049\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 5/5 [04:50<00:00, 58.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 4 | Average train loss: 0.048 | Avg test loss: 0.042\n",
            "CPU times: total: 8min 34s\n",
            "Wall time: 4min 50s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Train on CPU\n",
        "model_cpu = MNISTModelV0(input_shape=1,\n",
        "                         hidden_units = 10,\n",
        "                         output_shape= 10).to(\"cpu\")\n",
        "\n",
        "# Create loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model_cpu.parameters(), lr=0.1)\n",
        "\n",
        "### Training loop\n",
        "epochs = 5\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    train_loss = 0\n",
        "    for batch, (X,y) in enumerate(train_dataloader):\n",
        "        model_cpu.train()\n",
        "        \n",
        "        # Put the data on the CPU\n",
        "        X , y = X.to(\"cpu\"), y.to(\"cpu\")\n",
        "        #Forward pass\n",
        "        y_pred = model_cpu(X)\n",
        "        \n",
        "        #Loss calculation\n",
        "        loss= loss_fn(y_pred, y)\n",
        "        train_loss += loss\n",
        "        \n",
        "        # optimizer zero grad\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        #loss backward\n",
        "        loss.backward()\n",
        "        \n",
        "        #Optimizer step\n",
        "        optimizer.step()\n",
        "        \n",
        "    # Average train loss per batch\n",
        "    train_loss /= len(train_dataloader)\n",
        "    \n",
        "    ### Testing loop\n",
        "    total_test_loss = 0\n",
        "    #Put model in eval mode\n",
        "    model_cpu.eval()\n",
        "    \n",
        "    #Turn on inference mode\n",
        "    with torch.inference_mode():\n",
        "        for batch, (X_test,y_test) in enumerate(test_dataloader):\n",
        "            X_test, y_test = X_test.to(\"cpu\"), y_test.to(\"cpu\")\n",
        "            test_pred = model_cpu(X_test)\n",
        "            test_loss = loss_fn(test_pred, y_test)\n",
        "            \n",
        "            total_test_loss += test_loss \n",
        "        \n",
        "        total_test_loss /= len(test_dataloader)\n",
        "        \n",
        "    print(f\"Epoch: {epoch} | Average train loss: {train_loss:.3f} | Avg test loss: {total_test_loss:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "ename": "AssertionError",
          "evalue": "Torch not compiled with CUDA enabled",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "File \u001b[1;32m<timed exec>:4\u001b[0m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1141\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m   1143\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m-> 1145\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    816\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    817\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    818\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    819\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 820\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[0;32m    821\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    822\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1140\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[0;32m   1141\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m-> 1143\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\cuda\\__init__.py:239\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    236\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    237\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    238\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m'\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 239\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    240\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    241\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[0;32m    242\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "#Model on GPU\n",
        "model_gpu = MNISTModelV0(input_shape= 1,\n",
        "                        hidden_units= 10,\n",
        "                        output_shape= 10).to(\"cuda\")\n",
        "\n",
        "# Create loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model_gpu.parameers(), lr=0.1)\n",
        "\n",
        "### Training loop \n",
        "epochs = 5\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    train_loss = 0\n",
        "    for batch, (X,y) in enumerate(train_dataloader):\n",
        "        model_gpu.train()\n",
        "\n",
        "        X,y = X.to(\"cuda\"), y.to(\"cuda\")\n",
        "\n",
        "        #Forward pass\n",
        "        y_pred = model_gpu(X)\n",
        "\n",
        "        #Loss\n",
        "        loss = loss_fn(y_pred,y)\n",
        "        train_loss += loss\n",
        "\n",
        "        #optimizer zero grad\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #Loss backward\n",
        "        loss.backward()\n",
        "\n",
        "        #Optimizer step\n",
        "        optimizer.step()\n",
        "    \n",
        "    # Average train loss per batch\n",
        "    train_loss /= len(train_dataloader)\n",
        "\n",
        "    ### Testing loop\n",
        "    total_test_loss = 0\n",
        "    # Put the model in eval mode\n",
        "    model_gpu.eval()\n",
        "    # with torch inference mode\n",
        "    with torch.inference_mode():\n",
        "        for batch, (X_test,y_test) in enumerate(test_dataloader):\n",
        "            test_pred = model_gpu(X_test)\n",
        "\n",
        "            #Loss\n",
        "            test_loss = loss_fn(test_pred, y_test)\n",
        "            total_test_loss += test_loss\n",
        "\n",
        "        # Average loss per batch \n",
        "        total_test_loss /= len(test_dataloader)\n",
        "    print(f\"Epoch: {epoch} | Average train loss: {train_loss:.3f} | Avg test loss: {total_test_loss:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1CsHhPpxp1w"
      },
      "source": [
        "## 10. Make predictions using your trained model and visualize at least 5 of them comparing the prediciton to the target label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "_YGgZvSobNxu"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x1bb99d2a5f0>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(test_data[0][0].squeeze(0), cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([7])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Logits -> Prediction probabilities -> Predction labels\n",
        "model_pred_logits = model_cpu(test_data[0][0].unsqueeze(dim=0).to(device))\n",
        "model_pred_probs =  torch.softmax(model_pred_logits, dim=1)\n",
        "model_pred_labels = torch.argmax(model_pred_probs,dim=1)\n",
        "model_pred_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQwzqlBWxrpG"
      },
      "source": [
        "## 11. Plot a confusion matrix comparing your model's predictions to the truth labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSrXiT_AbQ6e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lj6bDhoWxt2y"
      },
      "source": [
        "## 12. Create a random tensor of shape `[1, 3, 64, 64]` and pass it through a `nn.Conv2d()` layer with various hyperparameter settings (these can be any settings you choose), what do you notice if the `kernel_size` parameter goes up and down?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leCTsqtSbR5P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHS20cNTxwSi"
      },
      "source": [
        "## 13. Use a model similar to the trained `model_2` from notebook 03 to make predictions on the test [`torchvision.datasets.FashionMNIST`](https://pytorch.org/vision/main/generated/torchvision.datasets.FashionMNIST.html) dataset. \n",
        "* Then plot some predictions where the model was wrong alongside what the label of the image should've been. \n",
        "* After visualing these predictions do you think it's more of a modelling error or a data error? \n",
        "* As in, could the model do better or are the labels of the data too close to each other (e.g. a \"Shirt\" label is too close to \"T-shirt/top\")?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78a8LjtdbSZj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMUsDcN/+FAm9Pf7Ifqs6AZ",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "03_pytorch_computer_vision_exercises.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
